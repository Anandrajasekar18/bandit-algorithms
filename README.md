# bandit-algorithms
## Mutli armed bandits
Implementation of epsilon-greedy, softmax policy and UCB1. 

### Prerequisites 
1) Numpy  
2) Matplotlib

### Usage
Download the directory and run the appropriate python file for the implementation of bandit algorithm with testbed of 10 arms for 1000 timesteps and 2000 plays. (Implementation of 10 armed testbed from Introduction to RL by Sutton and Barto)

![Plot comparing different algorithms - 10 arms](https://github.com/Anandrajasekar18/bandit-algorithms/blob/master/ucb10.png)





